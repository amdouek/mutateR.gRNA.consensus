% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/SHAP_targets.R
\name{compute_shap_targets}
\alias{compute_shap_targets}
\title{Compute target variables for SHAP analysis (Tiered Version)}
\usage{
compute_shap_targets(scores_df, modern_methods = NULL, legacy_methods = NULL)
}
\arguments{
\item{scores_df}{Data frame from score_grnas_multi()}

\item{modern_methods}{Character vector. Modern scoring methods.
Default: c("deepspcas9", "deephf", "ruleset3") for Cas9,
c("deepcpf1", "enpamgb") for Cas12a.}

\item{legacy_methods}{Character vector. Legacy methods to model separately.
Default: c("ruleset1") for Cas9, empty for Cas12a.}
}
\value{
Data frame with columns:
\describe{
\item{grna_id}{gRNA identifier}
\item{mean_score_modern}{Mean normalized score (modern methods)}
\item{mean_rank_modern}{Mean rank across modern methods (1 = best)}
\item{max_rank_modern}{Worst rank among modern methods}
\item{min_rank_modern}{Best rank among modern methods}
\item{rank_variance_modern}{Variance in ranks (modern methods)}
\item{rank_range_modern}{Range of ranks (modern methods)}
\item{quality_percentile_modern}{Percentile score (higher = better)}
\item{concordance_modern}{Agreement score (higher = more agreement)}
\item{discordance_modern}{Disagreement score (higher = more disagreement)}
\item{median_rank_all}{Median rank across all methods}
\item{trimmed_mean_rank_all}{Trimmed mean rank (robust)}
\item{quality_percentile_robust}{Median-based quality percentile}
\item{\if{html}{\out{<legacy>}}\emph{divergence}{Legacy method divergence from modern consensus}
\item{is_top20/50/100_modern}{Binary flags for top-ranked gRNAs}
\item{score}\if{html}{\out{<method>}}}{Raw scores for each method}
\item{rank_\if{html}{\out{<method>}}}{Ranks for each method}
}
}
\description{
Calculates outcome variables with explicit handling of modern vs. legacy
methods. Provides tiered consensus metrics for flexible analysis that
prevents legacy methods from dominating variance-based statistics.
}
\details{
The tiered approach addresses a key challenge: legacy methods (like RuleSet1)
may systematically differ from modern deep learning methods, which can
dominate simple variance-based consensus metrics.

\strong{Tier 1 - Modern Method Consensus:}
Metrics computed only among modern methods (DeepSpCas9, DeepHF, RuleSet3).
These methods show higher inter-correlation (~0.70) and likely better
reflect true gRNA efficacy.

\strong{Tier 2 - Robust Full Consensus:}
Metrics using all methods but with robust statistics (median, trimmed mean)
that resist influence from a single outlier method.

\strong{Tier 3 - Legacy Divergence:}
Explicit modeling of where legacy methods disagree with modern consensus.
Positive divergence means legacy ranks the gRNA worse than modern methods.

\strong{Tier 4 - Binary Selection Flags:}
Useful for classification tasks (e.g., "is this a top-50 gRNA?").
}
\examples{
\dontrun{
# Get multi-method scores
scores <- score_grnas_multi(sites)

# Compute all target variables
targets <- compute_shap_targets(scores)

# View available targets
names(targets)

# Use modern quality for primary analysis
y <- targets$quality_percentile_modern

# Analyze legacy divergence separately
y_legacy <- targets$ruleset1_divergence
}

}
\seealso{
\code{\link{extract_grna_features}} for feature computation,
\code{\link{analyze_feature_importance}} for SHAP analysis,
\code{\link{get_target_interpretation}} for target descriptions
}
